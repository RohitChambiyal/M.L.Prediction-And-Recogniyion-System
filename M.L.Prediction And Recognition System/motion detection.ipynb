{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'imutils'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-92c6e4c61fe1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# import the necessary packages\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mimutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvideo\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mVideoStream\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0margparse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'imutils'"
     ]
    }
   ],
   "source": [
    "\n",
    "# import the necessary packages\n",
    "from imutils.video import VideoStream\n",
    "import argparse\n",
    "import datetime\n",
    "import imutils\n",
    "import time\n",
    "import cv2\n",
    "\n",
    "# construct the argument parser and parse the arguments\n",
    "ap = argparse.ArgumentParser()\n",
    "ap.add_argument(\"-v\", \"--video\", help=\"path to the video file\")\n",
    "ap.add_argument(\"-a\", \"--min-area\", type=int, default=500, help=\"minimum area size\")\n",
    "args = vars(ap.parse_args())\n",
    "\n",
    "# if the video argument is None, then we are reading from webcam\n",
    "if args.get(\"video\", None) is None:\n",
    "    vs = VideoStream(src=0).start()\n",
    "    time.sleep(2.0)\n",
    "\n",
    "# otherwise, we are reading from a video file\n",
    "else:\n",
    "    vs = cv2.VideoCapture(args[\"video\"])\n",
    "\n",
    "# initialize the first frame in the video stream\n",
    "firstFrame = None\n",
    "1\n",
    "2\n",
    "3\n",
    "4\n",
    "5\n",
    "6\n",
    "7\n",
    "8\n",
    "9\n",
    "10\n",
    "11\n",
    "12\n",
    "13\n",
    "14\n",
    "15\n",
    "16\n",
    "17\n",
    "18\n",
    "19\n",
    "20\n",
    "21\n",
    "22\n",
    "23\n",
    "24\n",
    "25\n",
    "\t\n",
    "# import the necessary packages\n",
    "from imutils.video import VideoStream\n",
    "import argparse\n",
    "import datetime\n",
    "import imutils\n",
    "import time\n",
    "import cv2\n",
    " \n",
    "# construct the argument parser and parse the arguments\n",
    "ap = argparse.ArgumentParser()\n",
    "ap.add_argument(\"-v\", \"--video\", help=\"path to the video file\")\n",
    "ap.add_argument(\"-a\", \"--min-area\", type=int, default=500, help=\"minimum area size\")\n",
    "args = vars(ap.parse_args())\n",
    " \n",
    "# if the video argument is None, then we are reading from webcam\n",
    "if args.get(\"video\", None) is None:\n",
    "\tvs = VideoStream(src=0).start()\n",
    "\ttime.sleep(2.0)\n",
    " \n",
    "# otherwise, we are reading from a video file\n",
    "else:\n",
    "\tvs = cv2.VideoCapture(args[\"video\"])\n",
    " \n",
    "# initialize the first frame in the video stream\n",
    "firstFrame = None\n",
    "\n",
    "\n",
    "# loop over the frames of the video\n",
    "while True:\n",
    "\t# grab the current frame and initialize the occupied/unoccupied\n",
    "\t# text\n",
    "\tframe = vs.read()\n",
    "\tframe = frame if args.get(\"video\", None) is None else frame[1]\n",
    "\ttext = \"Unoccupied\"\n",
    "\n",
    "\t# if the frame could not be grabbed, then we have reached the end\n",
    "\t# of the video\n",
    "\tif frame is None:\n",
    "\t\tbreak\n",
    "\n",
    "\t# resize the frame, convert it to grayscale, and blur it\n",
    "\tframe = imutils.resize(frame, width=500)\n",
    "\tgray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\tgray = cv2.GaussianBlur(gray, (21, 21), 0)\n",
    "\n",
    "\t# if the first frame is None, initialize it\n",
    "\tif firstFrame is None:\n",
    "\t\tfirstFrame = gray\n",
    "\t\tcontinue\n",
    "27\n",
    "28\n",
    "29\n",
    "30\n",
    "31\n",
    "32\n",
    "33\n",
    "34\n",
    "35\n",
    "36\n",
    "37\n",
    "38\n",
    "39\n",
    "40\n",
    "41\n",
    "42\n",
    "43\n",
    "44\n",
    "45\n",
    "46\n",
    "47\n",
    "48\n",
    "\t\n",
    "# loop over the frames of the video\n",
    "while True:\n",
    "\t# grab the current frame and initialize the occupied/unoccupied\n",
    "\t# text\n",
    "\tframe = vs.read()\n",
    "\tframe = frame if args.get(\"video\", None) is None else frame[1]\n",
    "\ttext = \"Unoccupied\"\n",
    " \n",
    "\t# if the frame could not be grabbed, then we have reached the end\n",
    "\t# of the video\n",
    "\tif frame is None:\n",
    "\t\tbreak\n",
    " \n",
    "\t# resize the frame, convert it to grayscale, and blur it\n",
    "\tframe = imutils.resize(frame, width=500)\n",
    "\tgray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\tgray = cv2.GaussianBlur(gray, (21, 21), 0)\n",
    " \n",
    "\t# if the first frame is None, initialize it\n",
    "\tif firstFrame is None:\n",
    "\t\tfirstFrame = gray\n",
    "\t\tcontinue\n",
    "        \t# compute the absolute difference between the current frame and\n",
    "\t# first frame\n",
    "\tframeDelta = cv2.absdiff(firstFrame, gray)\n",
    "\tthresh = cv2.threshold(frameDelta, 25, 255, cv2.THRESH_BINARY)[1]\n",
    " \n",
    "\t# dilate the thresholded image to fill in holes, then find contours\n",
    "\t# on thresholded image\n",
    "\tthresh = cv2.dilate(thresh, None, iterations=2)\n",
    "\tcnts = cv2.findContours(thresh.copy(), cv2.RETR_EXTERNAL,\n",
    "\t\tcv2.CHAIN_APPROX_SIMPLE)\n",
    "\tcnts = imutils.grab_contours(cnts)\n",
    " \n",
    "\t# loop over the contours\n",
    "\tfor c in cnts:\n",
    "\t\t# if the contour is too small, ignore it\n",
    "\t\tif cv2.contourArea(c) < args[\"min_area\"]:\n",
    "\t\t\tcontinue\n",
    " \n",
    "\t\t# compute the bounding box for the contour, draw it on the frame,\n",
    "\t\t# and update the text\n",
    "\t\t(x, y, w, h) = cv2.boundingRect(c)\n",
    "\t\tcv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\t\ttext = \"Occupied\"\n",
    "        \t# draw the text and timestamp on the frame\n",
    "\tcv2.putText(frame, \"Room Status: {}\".format(text), (10, 20),\n",
    "\t\tcv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 2)\n",
    "\tcv2.putText(frame, datetime.datetime.now().strftime(\"%A %d %B %Y %I:%M:%S%p\"),\n",
    "\t\t(10, frame.shape[0] - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.35, (0, 0, 255), 1)\n",
    " \n",
    "\t# show the frame and record if the user presses a key\n",
    "\tcv2.imshow(\"Security Feed\", frame)\n",
    "\tcv2.imshow(\"Thresh\", thresh)\n",
    "\tcv2.imshow(\"Frame Delta\", frameDelta)\n",
    "\tkey = cv2.waitKey(1) & 0xFF\n",
    " \n",
    "\t# if the `q` key is pressed, break from the lop\n",
    "\tif key == ord(\"q\"):\n",
    "\t\tbreak\n",
    " \n",
    "# cleanup the camera and close any open windows\n",
    "vs.stop() if args.get(\"video\", None) is None else vs.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Escape hit, closing...\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "cam = cv2.VideoCapture(0)\n",
    "\n",
    "cv2.namedWindow(\"test\")\n",
    "\n",
    "img_counter = 0\n",
    "\n",
    "while True:\n",
    "    ret, frame = cam.read()\n",
    "    cv2.imshow(\"test\", frame)\n",
    "    if not ret:\n",
    "        break\n",
    "    k = cv2.waitKey(1)\n",
    "\n",
    "    if k%256 == 27:\n",
    "        # ESC pressed\n",
    "        print(\"Escape hit, closing...\")\n",
    "        break\n",
    "    elif k%256 == 32:\n",
    "        # SPACE pressed\n",
    "        img_name = \"opencv_frame_{}.png\".format(img_counter)\n",
    "        cv2.imwrite(img_name, frame)\n",
    "        print(\"{} written!\".format(img_name))\n",
    "        img_counter += 1\n",
    "\n",
    "cam.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "face_cascade = cv2.CascadeClassifier('haarcascadeface.xml')\n",
    "eye_cascade = cv2.CascadeClassifier('haarcascadeeye.xml')\n",
    "\n",
    "#this is the cascade we just made. Call what you want\n",
    "watch_cascade = cv2.CascadeClassifier('stage9.xml')\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while 1:\n",
    "    ret, img = cap.read()\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "    \n",
    "    # add this\n",
    "    # image, reject levels level weights.\n",
    "    watches = watch_cascade.detectMultiScale(gray, 50, 50)\n",
    "    \n",
    "    # add this\n",
    "    for (x,y,w,h) in watches:\n",
    "        cv2.rectangle(img,(x,y),(x+w,y+h),(255,255,0),2)\n",
    "\n",
    "    #for (x,y,w,h) in faces:\n",
    "     #   cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "\n",
    "        \n",
    "        roi_gray = gray[y:y+h, x:x+w]\n",
    "        roi_color = img[y:y+h, x:x+w]\n",
    "        eyes = eye_cascade.detectMultiScale(roi_gray)\n",
    "      #  for (ex,ey,ew,eh) in eyes:\n",
    "       #     cv2.rectangle(roi_color,(ex,ey),(ex+ew,ey+eh),(0,255,0),2)\n",
    "\n",
    "    cv2.imshow('img',img)\n",
    "    k = cv2.waitKey(30) & 0xff\n",
    "    if k == 27:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Motion detected.. Do something!!!\n",
      "Motion detected.. Do something!!!\n",
      "Motion detected.. Do something!!!\n",
      "Motion detected.. Do something!!!\n",
      "Motion detected.. Do something!!!\n",
      "Motion detected.. Do something!!!\n",
      "Motion detected.. Do something!!!\n",
      "Motion detected.. Do something!!!\n",
      "Motion detected.. Do something!!!\n",
      "Motion detected.. Do something!!!\n",
      "Motion detected.. Do something!!!\n",
      "Motion detected.. Do something!!!\n",
      "Motion detected.. Do something!!!\n",
      "Motion detected.. Do something!!!\n",
      "Motion detected.. Do something!!!\n",
      "Motion detected.. Do something!!!\n",
      "Motion detected.. Do something!!!\n",
      "Motion detected.. Do something!!!\n",
      "Motion detected.. Do something!!!\n",
      "Motion detected.. Do something!!!\n",
      "Motion detected.. Do something!!!\n",
      "Motion detected.. Do something!!!\n",
      "Motion detected.. Do something!!!\n",
      "Motion detected.. Do something!!!\n",
      "Motion detected.. Do something!!!\n",
      "Motion detected.. Do something!!!\n",
      "Motion detected.. Do something!!!\n",
      "Motion detected.. Do something!!!\n",
      "Motion detected.. Do something!!!\n",
      "Motion detected.. Do something!!!\n",
      "Motion detected.. Do something!!!\n",
      "Motion detected.. Do something!!!\n",
      "Motion detected.. Do something!!!\n",
      "Motion detected.. Do something!!!\n",
      "Motion detected.. Do something!!!\n",
      "Motion detected.. Do something!!!\n",
      "Motion detected.. Do something!!!\n",
      "Motion detected.. Do something!!!\n",
      "Motion detected.. Do something!!!\n",
      "Motion detected.. Do something!!!\n",
      "Motion detected.. Do something!!!\n",
      "Motion detected.. Do something!!!\n",
      "Motion detected.. Do something!!!\n",
      "Motion detected.. Do something!!!\n",
      "Motion detected.. Do something!!!\n",
      "Motion detected.. Do something!!!\n",
      "Motion detected.. Do something!!!\n",
      "Motion detected.. Do something!!!\n",
      "Motion detected.. Do something!!!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "sdThresh = 10\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "#TODO: Face Detection 1\n",
    "\n",
    "def distMap(frame1, frame2):\n",
    "    \"\"\"outputs pythagorean distance between two frames\"\"\"\n",
    "    frame1_32 = np.float32(frame1)\n",
    "    frame2_32 = np.float32(frame2)\n",
    "    diff32 = frame1_32 - frame2_32\n",
    "    norm32 = np.sqrt(diff32[:,:,0]**2 + diff32[:,:,1]**2 + diff32[:,:,2]**2)/np.sqrt(255**2 + 255**2 + 255**2)\n",
    "    dist = np.uint8(norm32*255)\n",
    "    return dist\n",
    "\n",
    "cv2.namedWindow('frame')\n",
    "cv2.namedWindow('dist')\n",
    "\n",
    "#capture video stream from camera source. 0 refers to first camera, 1 referes to 2nd and so on.\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "_, frame1 = cap.read()\n",
    "_, frame2 = cap.read()\n",
    "\n",
    "facecount = 0\n",
    "while(True):\n",
    "    _, frame3 = cap.read()\n",
    "    rows, cols, _ = np.shape(frame3)\n",
    "    cv2.imshow('dist', frame3)\n",
    "    dist = distMap(frame1, frame3)\n",
    "\n",
    "    frame1 = frame2\n",
    "    frame2 = frame3\n",
    "\n",
    "    # apply Gaussian smoothing\n",
    "    mod = cv2.GaussianBlur(dist, (9,9), 0)\n",
    "\n",
    "    # apply thresholding\n",
    "    _, thresh = cv2.threshold(mod, 100, 255, 0)\n",
    "\n",
    "    # calculate st dev test\n",
    "    _, stDev = cv2.meanStdDev(mod)\n",
    "\n",
    "    cv2.imshow('dist', mod)\n",
    "    cv2.putText(frame2, \"Standard Deviation - {}\".format(round(stDev[0][0],0)), (70, 70), font, 1, (255, 0, 255), 1, cv2.LINE_AA)\n",
    "    if stDev > sdThresh:\n",
    "            print(\"Motion detected.. Do something!!!\");\n",
    "            #TODO: Face Detection 2\n",
    "\n",
    "    cv2.imshow('frame', frame2)\n",
    "    if cv2.waitKey(1) & 0xFF == 27:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "https://www.youtube.com/watch?v=J81JFwqsS5o"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
